{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rishi\\AppData\\Local\\Temp\\ipykernel_28836\\3579895535.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the csv with recording locations, ID, outcome\n",
    "#C:\\Users\\rishi\\OneDrive - Monash University\\Documents\\Monash\\Sonorus\\sonorus - physionet data\n",
    "df = pd.read_csv(r\"C:\\Users\\rishi\\OneDrive - Monash University\\Documents\\Monash\\Sonorus\\sonorus - physionet data\\Data\\training_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient ID</th>\n",
       "      <th>Recording locations:</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Pregnancy status</th>\n",
       "      <th>Murmur</th>\n",
       "      <th>Murmur locations</th>\n",
       "      <th>Most audible location</th>\n",
       "      <th>...</th>\n",
       "      <th>Systolic murmur pitch</th>\n",
       "      <th>Systolic murmur quality</th>\n",
       "      <th>Diastolic murmur timing</th>\n",
       "      <th>Diastolic murmur shape</th>\n",
       "      <th>Diastolic murmur grading</th>\n",
       "      <th>Diastolic murmur pitch</th>\n",
       "      <th>Diastolic murmur quality</th>\n",
       "      <th>Outcome</th>\n",
       "      <th>Campaign</th>\n",
       "      <th>Additional ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2530</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>False</td>\n",
       "      <td>Absent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9979</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Female</td>\n",
       "      <td>103.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>Harsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9983</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>115.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>False</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13918</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>98.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>TV</td>\n",
       "      <td>TV</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Blowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14241</td>\n",
       "      <td>AV+PV+TV+MV</td>\n",
       "      <td>Child</td>\n",
       "      <td>Male</td>\n",
       "      <td>87.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>False</td>\n",
       "      <td>Present</td>\n",
       "      <td>AV+MV+PV+TV</td>\n",
       "      <td>PV</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>Harsh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>CC2015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient ID Recording locations:    Age     Sex  Height  Weight  \\\n",
       "0        2530          AV+PV+TV+MV  Child  Female    98.0    15.9   \n",
       "1        9979          AV+PV+TV+MV  Child  Female   103.0    13.1   \n",
       "2        9983          AV+PV+TV+MV  Child    Male   115.0    19.1   \n",
       "3       13918          AV+PV+TV+MV  Child    Male    98.0    15.9   \n",
       "4       14241          AV+PV+TV+MV  Child    Male    87.0    11.2   \n",
       "\n",
       "   Pregnancy status   Murmur Murmur locations Most audible location  ...  \\\n",
       "0             False   Absent              NaN                   NaN  ...   \n",
       "1             False  Present      AV+MV+PV+TV                    TV  ...   \n",
       "2             False  Unknown              NaN                   NaN  ...   \n",
       "3             False  Present               TV                    TV  ...   \n",
       "4             False  Present      AV+MV+PV+TV                    PV  ...   \n",
       "\n",
       "  Systolic murmur pitch Systolic murmur quality Diastolic murmur timing  \\\n",
       "0                   NaN                     NaN                     NaN   \n",
       "1                  High                   Harsh                     NaN   \n",
       "2                   NaN                     NaN                     NaN   \n",
       "3                   Low                 Blowing                     NaN   \n",
       "4                   Low                   Harsh                     NaN   \n",
       "\n",
       "  Diastolic murmur shape Diastolic murmur grading Diastolic murmur pitch  \\\n",
       "0                    NaN                      NaN                    NaN   \n",
       "1                    NaN                      NaN                    NaN   \n",
       "2                    NaN                      NaN                    NaN   \n",
       "3                    NaN                      NaN                    NaN   \n",
       "4                    NaN                      NaN                    NaN   \n",
       "\n",
       "  Diastolic murmur quality   Outcome Campaign Additional ID  \n",
       "0                      NaN  Abnormal   CC2015           NaN  \n",
       "1                      NaN  Abnormal   CC2015           NaN  \n",
       "2                      NaN  Abnormal   CC2015           NaN  \n",
       "3                      NaN  Abnormal   CC2015           NaN  \n",
       "4                      NaN  Abnormal   CC2015           NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Outcome\n",
       "Normal      486\n",
       "Abnormal    456\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Outcome\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_array(data, signal_length = None):\n",
    "    max_len = 0\n",
    "    for i in data:\n",
    "        if len(i) > max_len:\n",
    "            max_len = len(i)\n",
    "    if not signal_length == None:\n",
    "        max_len = signal_length\n",
    "    new_arr = np.zeros((len(data),max_len))\n",
    "    for j in range(len(data)):\n",
    "        if len(data[j]) > max_len:\n",
    "            new_arr[j,:] = data[j][:max_len]\n",
    "        else:\n",
    "            new_arr[j,:len(data[j])] = data[j]\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_signal(data, max_len = int(1*355712)):\n",
    "    #pad_length - 1422490 = max_length of the signals in the dataset\n",
    "    #pad_length after spectrogram = 355712 = max length of the spectrograms\n",
    "    new_arr = np.zeros(max_len)\n",
    "    if len(data) > max_len:\n",
    "        new_arr = data[:max_len]\n",
    "    else:\n",
    "        new_arr[:len(data)] = data\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flat Specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all files that starts with the ID and ends with .wav\n",
    "#make a list of lists for each ID\n",
    "outcome_classes = [\"Normal\", \"Abnormal\"]\n",
    "specs = []\n",
    "#wav_files = []\n",
    "outcomes = []\n",
    "for i in range(df.shape[0]):\n",
    "    patient_ID = df[\"Patient ID\"][i]\n",
    "    outcome = df[\"Outcome\"][i]\n",
    "    specs_for_each_patient = []\n",
    "    #wav_file_for_each_patient = []\n",
    "    number_of_recordings = 0\n",
    "    data_directory = \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/circor dataset/the-circor-digiscope-phonocardiogram-dataset-1.0.3/training_data\"\n",
    "\n",
    "\n",
    "    for root, dirs, files in os.walk(data_directory):\n",
    "        for file in files:\n",
    "\n",
    "            if re.search(\"^\" + str(patient_ID) + \"[A-Z_]{3}.wav$\", file):\n",
    "                number_of_recordings += 1\n",
    "                #load wav file\n",
    "                audio_signal, sampling_rate = librosa.load(data_directory + '/'+ file)\n",
    "                \n",
    "                #get the spectrogram\n",
    "                spec = librosa.feature.melspectrogram(y=audio_signal, sr=sampling_rate)\n",
    "                spec = spec.flatten()\n",
    "\n",
    "                #pad spectrogram - pad after taking spectrogram because \n",
    "                #the length of spectrogram is different for each audio signal(even if len of audio signal is same)\n",
    "                #we need data with same length for training\n",
    "                padded_spec = pad_signal(spec)\n",
    "\n",
    "                specs_for_each_patient.append(padded_spec)\n",
    "                #wav_file_for_each_patient.append(audio_signal)\n",
    "\n",
    "    #add outcome for each patient\n",
    "    current_outcome = np.zeros(2, dtype=int)\n",
    "    j = outcome_classes.index(outcome)\n",
    "    current_outcome[j] = 1\n",
    "\n",
    "    for i in range(number_of_recordings):\n",
    "        outcomes.append(current_outcome) #add the outcome for each location of a patient\n",
    "\n",
    "    #wav_files += wav_file_for_each_patient\n",
    "    specs += specs_for_each_patient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not flat specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all files that starts with the ID and ends with .wav\n",
    "#make a list of lists for each ID\n",
    "outcome_classes = [\"Normal\", \"Abnormal\"]\n",
    "specs = []\n",
    "#wav_files = []\n",
    "outcomes = []\n",
    "for i in range(df.shape[0]):\n",
    "    patient_ID = df[\"Patient ID\"][i]\n",
    "    outcome = df[\"Outcome\"][i]\n",
    "    specs_for_each_patient = []\n",
    "    #wav_file_for_each_patient = []\n",
    "    number_of_recordings = 0\n",
    "    data_directory = \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/circor dataset/the-circor-digiscope-phonocardiogram-dataset-1.0.3/training_data\"\n",
    "\n",
    "\n",
    "    for root, dirs, files in os.walk(data_directory):\n",
    "        for file in files:\n",
    "\n",
    "            if re.search(\"^\" + str(patient_ID) + \"[A-Z_]{3}.wav$\", file):\n",
    "                number_of_recordings += 1\n",
    "                #load wav file\n",
    "                audio_signal, sampling_rate = librosa.load(data_directory + '/'+ file)\n",
    "                padded_spec = pad_signal(audio_signal, max_len=1422490)\n",
    "\n",
    "                #get the spectrogram\n",
    "                spec = librosa.feature.melspectrogram(y=padded_spec, sr=sampling_rate)\n",
    "                #spec = spec.flatten()\n",
    "\n",
    "                #pad spectrogram - pad after taking spectrogram because \n",
    "                #the length of spectrogram is different for each audio signal(even if len of audio signal is same)\n",
    "                #we need data with same length for training\n",
    "                #\n",
    "\n",
    "                specs_for_each_patient.append(spec)\n",
    "                #wav_file_for_each_patient.append(audio_signal)\n",
    "\n",
    "    #add outcome for each patient\n",
    "    current_outcome = np.zeros(2, dtype=int)\n",
    "    j = outcome_classes.index(outcome)\n",
    "    current_outcome[j] = 1\n",
    "\n",
    "    for i in range(number_of_recordings):\n",
    "        outcomes.append(current_outcome) #add the outcome for each location of a patient\n",
    "\n",
    "    #wav_files += wav_file_for_each_patient\n",
    "    specs += specs_for_each_patient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = np.load(r\"Preprocessed data/specs.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = np.load(r\"Preprocessed data/outcomes_array.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Short not flat spectograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all files that starts with the ID and ends with .wav\n",
    "#make a list of lists for each ID\n",
    "outcome_classes = [\"Normal\", \"Abnormal\"]\n",
    "specs = []\n",
    "#wav_files = []\n",
    "outcomes = []\n",
    "for i in range(df.shape[0]): #\n",
    "    patient_ID = df[\"Patient ID\"][i]\n",
    "    outcome = df[\"Outcome\"][i]\n",
    "    specs_for_each_patient = []\n",
    "    #wav_file_for_each_patient = []\n",
    "    number_of_recordings = 0\n",
    "    data_directory = \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/circor dataset/the-circor-digiscope-phonocardiogram-dataset-1.0.3/training_data\"\n",
    "\n",
    "\n",
    "    for root, dirs, files in os.walk(data_directory):\n",
    "        for file in files:\n",
    "\n",
    "            if re.search(\"^\" + str(patient_ID) + \"[A-Z_]{3}.wav$\", file):\n",
    "                number_of_recordings += 1\n",
    "                #load wav file\n",
    "                audio_signal, sampling_rate = librosa.load(data_directory + '/'+ file)\n",
    "                \n",
    "                #length of the file = time in sec * sample_rate\n",
    "                #sample rate = samples(data points) per second\n",
    "                #lets take 10 sec sample\n",
    "                #max_len = 10 * sampling_rate\n",
    "                padded_audio = pad_signal(audio_signal, max_len=10*sampling_rate)\n",
    "\n",
    "                #get the spectrogram\n",
    "                spec = librosa.feature.melspectrogram(y=padded_audio, sr=sampling_rate)\n",
    "                #spec = spec.flatten()\n",
    "\n",
    "                #pad spectrogram - pad after taking spectrogram because \n",
    "                #the length of spectrogram is different for each audio signal(even if len of audio signal is same)\n",
    "                #we need data with same length for training\n",
    "                #\n",
    "\n",
    "                specs_for_each_patient.append(spec)\n",
    "                #wav_file_for_each_patient.append(audio_signal)\n",
    "\n",
    "    #add outcome for each patient\n",
    "    current_outcome = np.zeros(2, dtype=int)\n",
    "    j = outcome_classes.index(outcome)\n",
    "    current_outcome[j] = 1\n",
    "\n",
    "    for i in range(number_of_recordings):\n",
    "        outcomes.append(current_outcome) #add the outcome for each location of a patient\n",
    "\n",
    "    #wav_files += wav_file_for_each_patient\n",
    "    specs += specs_for_each_patient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3118"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 431)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "specs = np.array(specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of channels in each sample is 1 in grayscale image\n",
    "#CNN requires 4D input (batch_size, height, width, channels)\n",
    "specs = specs.reshape(specs.shape[0], specs.shape[1], specs.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing\n",
    "specs_train, specs_test, outcomes_train, outcomes_test = train_test_split(specs, outcomes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/Preprocessed data/specs_train_s.npy\",\n",
    "        specs_train)\n",
    "np.save( \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/Preprocessed data/specs_test_S.npy\",\n",
    "        specs_test)\n",
    "np.save( \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/Preprocessed data/outcomes_train.npy\",\n",
    "        outcomes_train)\n",
    "np.save( \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/Preprocessed data/outcomes_test.npy\",\n",
    "        outcomes_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/specs.npy\",\n",
    "        specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/outcomes_array.npy\",\n",
    "        np.array(outcomes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Window segment split 5 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "#get indices for training and testing set before segmentation\n",
    "#so that a patients info is not present in both training and testing set\n",
    "train_index = random.sample(range(df.shape[0]), int(df.shape[0]*0.8))\n",
    "test_index = list(set(range(df.shape[0])) - set(train_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------preprocessing train data\n",
    "#get all files that starts with the ID and ends with .wav\n",
    "#make a list of lists for each ID\n",
    "outcome_classes = [\"Normal\", \"Abnormal\"]\n",
    "specs = []\n",
    "#wav_files = []\n",
    "outcomes = []\n",
    "for i in train_index: #\n",
    "    patient_ID = df[\"Patient ID\"][i]\n",
    "    outcome = df[\"Outcome\"][i]\n",
    "    specs_for_each_patient = []\n",
    "    #wav_file_for_each_patient = []\n",
    "    number_of_recordings = 0\n",
    "    data_directory = r\"C:\\Users\\rishi\\OneDrive - Monash University\\Documents\\Monash\\Sonorus\\sonorus - physionet data\\Data\\training_data\"\n",
    "\n",
    "\n",
    "    for root, dirs, files in os.walk(data_directory):\n",
    "        for file in files:\n",
    "\n",
    "            if re.search(\"^\" + str(patient_ID) + \"[A-Z_]{3}.wav$\", file):\n",
    "                #for loop - range = audio_len/5. \n",
    "                \n",
    "                #load wav file\n",
    "                audio_signal, sampling_rate = librosa.load(data_directory + '/'+ file)\n",
    "\n",
    "                for i in range(0, len(audio_signal), 5*sampling_rate):\n",
    "                    audio_signal_chunk = audio_signal[i:i+5*sampling_rate]\n",
    "                    #you dont need the step below ????\n",
    "                    padded_audio = pad_signal(audio_signal_chunk, max_len=5*sampling_rate)\n",
    "\n",
    "                    #get the spectrogram\n",
    "                    spec = librosa.feature.melspectrogram(y=padded_audio, sr=sampling_rate)\n",
    "\n",
    "                    specs_for_each_patient.append(spec)\n",
    "                    number_of_recordings += 1\n",
    "\n",
    "                \n",
    "\n",
    "    #add outcome for each patient\n",
    "    current_outcome = np.zeros(2, dtype=int)\n",
    "    j = outcome_classes.index(outcome)\n",
    "    current_outcome[j] = 1\n",
    "\n",
    "    for i in range(number_of_recordings):\n",
    "        outcomes.append(current_outcome) #add the outcome for each location of a patient\n",
    "\n",
    "    #wav_files += wav_file_for_each_patient\n",
    "    specs += specs_for_each_patient\n",
    "\n",
    "train_physionet_specs = np.array(specs)\n",
    "train_physionet_outcome = outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------preprocessing for test data\n",
    "#get all files that starts with the ID and ends with .wav\n",
    "#make a list of lists for each ID\n",
    "outcome_classes = [\"Normal\", \"Abnormal\"]\n",
    "specs = []\n",
    "#wav_files = []\n",
    "outcomes = []\n",
    "for i in test_index: #\n",
    "    patient_ID = df[\"Patient ID\"][i]\n",
    "    outcome = df[\"Outcome\"][i]\n",
    "    specs_for_each_patient = []\n",
    "    #wav_file_for_each_patient = []\n",
    "    number_of_recordings = 0\n",
    "    data_directory = r\"C:\\Users\\rishi\\OneDrive - Monash University\\Documents\\Monash\\Sonorus\\sonorus - physionet data\\Data\\training_data\"\n",
    "\n",
    "\n",
    "    for root, dirs, files in os.walk(data_directory):\n",
    "        for file in files:\n",
    "\n",
    "            if re.search(\"^\" + str(patient_ID) + \"[A-Z_]{3}.wav$\", file):\n",
    "                #for loop - range = audio_len/5. \n",
    "                \n",
    "                #load wav file\n",
    "                audio_signal, sampling_rate = librosa.load(data_directory + '/'+ file)\n",
    "\n",
    "                for i in range(0, len(audio_signal), 5*sampling_rate):\n",
    "                    audio_signal_chunk = audio_signal[i:i+5*sampling_rate]\n",
    "                    #you dont need the step below ????\n",
    "                    padded_audio = pad_signal(audio_signal_chunk, max_len=5*sampling_rate)\n",
    "\n",
    "                    #get the spectrogram\n",
    "                    spec = librosa.feature.melspectrogram(y=padded_audio, sr=sampling_rate)\n",
    "\n",
    "                    specs_for_each_patient.append(spec)\n",
    "                    number_of_recordings += 1\n",
    "\n",
    "                \n",
    "\n",
    "    #add outcome for each patient\n",
    "    current_outcome = np.zeros(2, dtype=int)\n",
    "    j = outcome_classes.index(outcome)\n",
    "    current_outcome[j] = 1\n",
    "\n",
    "    for i in range(number_of_recordings):\n",
    "        outcomes.append(current_outcome) #add the outcome for each location of a patient\n",
    "\n",
    "    #wav_files += wav_file_for_each_patient\n",
    "    specs += specs_for_each_patient\n",
    "\n",
    "test_physionet_specs = np.array(specs)\n",
    "test_physionet_outcome = outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12560, 128, 216) (3290, 128, 216)\n",
      "12560 3290\n"
     ]
    }
   ],
   "source": [
    "print(train_physionet_specs.shape, test_physionet_specs.shape)\n",
    "print(len(train_physionet_outcome), len(test_physionet_outcome))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save( r\"C:\\Users\\rishi\\OneDrive - Monash University\\Documents\\Monash\\Sonorus\\sonorus - physionet data\\Preprocessed data\\Segmented\\train_physionet_specs_segmented.npy\",\n",
    "        train_physionet_specs)\n",
    "np.save( r\"C:\\Users\\rishi\\OneDrive - Monash University\\Documents\\Monash\\Sonorus\\sonorus - physionet data\\Preprocessed data\\Segmented\\train_physionet_outcome_segmented.npy\",\n",
    "        train_physionet_outcome)\n",
    "np.save( r\"C:\\Users\\rishi\\OneDrive - Monash University\\Documents\\Monash\\Sonorus\\sonorus - physionet data\\Preprocessed data\\Segmented\\test_physionet_specs_segmented.npy\",\n",
    "        test_physionet_specs)\n",
    "np.save( r\"C:\\Users\\rishi\\OneDrive - Monash University\\Documents\\Monash\\Sonorus\\sonorus - physionet data\\Preprocessed data\\Segmented\\test_physionet_outcome_segmented.npy\",\n",
    "        test_physionet_outcome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont need this\n",
    "#splitting the data into training and testing\n",
    "specs_train, specs_test, outcomes_train, outcomes_test = train_test_split(specs, outcomes, test_size=0.2, random_state=42)\n",
    "\n",
    "np.save( \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/sonorus - physionet data/Preprocessed data/specs_train_segmented.npy\",\n",
    "        specs_train)\n",
    "np.save( \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/sonorus - physionet data/Preprocessed data/specs_test_segmented.npy\",\n",
    "        specs_test)\n",
    "np.save( \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/sonorus - physionet data/Preprocessed data/outcomes_train_segmented.npy\",\n",
    "        outcomes_train)\n",
    "np.save( \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/sonorus - physionet data/Preprocessed data/outcomes_test_segmented.npy\",\n",
    "        outcomes_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all files that starts with the ID and ends with .wav\n",
    "#make a list of lists for each ID\n",
    "outcome_classes = [\"Normal\", \"Abnormal\"]\n",
    "#specs = []\n",
    "wav_files = []\n",
    "outcomes = []\n",
    "for i in range(df.shape[0]):\n",
    "    patient_ID = df[\"Patient ID\"][i]\n",
    "    outcome = df[\"Outcome\"][i]\n",
    "    specs_for_each_patient = []\n",
    "    wav_file_for_each_patient = []\n",
    "    number_of_recordings = 0\n",
    "    data_directory = \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/circor dataset/the-circor-digiscope-phonocardiogram-dataset-1.0.3/training_data\"\n",
    "\n",
    "\n",
    "    for root, dirs, files in os.walk(data_directory):\n",
    "        for file in files:\n",
    "\n",
    "            if re.search(\"^\" + str(patient_ID) + \"[A-Z_]{3}.wav$\", file):\n",
    "                number_of_recordings += 1\n",
    "                #load wav file\n",
    "                audio_signal, sampling_rate = librosa.load(data_directory + '/'+ file)\n",
    "                \n",
    "                #get the spectrogram\n",
    "                #spec = librosa.feature.melspectrogram(y=audio_signal, sr=sampling_rate)\n",
    "                #spec = spec.flatten()\n",
    "\n",
    "                #pad spectrogram - pad after taking spectrogram because \n",
    "                #the length of spectrogram is different for each audio signal(even if len of audio signal is same)\n",
    "                #we need data with same length for training\n",
    "                padded_audio = pad_signal(audio_signal, max_len=1422490)\n",
    "\n",
    "                #specs_for_each_patient.append(padded_spec)\n",
    "                wav_file_for_each_patient.append(padded_audio)\n",
    "\n",
    "    #add outcome for each patient\n",
    "    current_outcome = np.zeros(2, dtype=int)\n",
    "    j = outcome_classes.index(outcome)\n",
    "    current_outcome[j] = 1\n",
    "\n",
    "    for i in range(number_of_recordings):\n",
    "        outcomes.append(current_outcome) #add the outcome for each location of a patient\n",
    "\n",
    "    wav_files += wav_file_for_each_patient\n",
    "    #specs += specs_for_each_patient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 33.0 GiB for an array with shape (3118, 1422490) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m wav_files \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwav_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 33.0 GiB for an array with shape (3118, 1422490) and data type float64"
     ]
    }
   ],
   "source": [
    "wav_files = np.array(wav_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 33.0 GiB for an array with shape (3118, 1422490) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/wav_files.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwav_files\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rishi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\npyio.py:545\u001b[0m, in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    542\u001b[0m     file_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[1;32m--> 545\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_array(fid, arr, allow_pickle\u001b[38;5;241m=\u001b[39mallow_pickle,\n\u001b[0;32m    547\u001b[0m                        pickle_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(fix_imports\u001b[38;5;241m=\u001b[39mfix_imports))\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 33.0 GiB for an array with shape (3118, 1422490) and data type float64"
     ]
    }
   ],
   "source": [
    "np.save( \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/wav_files.npy\",\n",
    "        wav_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all files that starts with the ID and ends with .wav\n",
    "#make a list of lists for each ID\n",
    "outcome_classes = [\"Normal\", \"Abnormal\"]\n",
    "specs = np.array([])\n",
    "#wav_files = []\n",
    "outcomes = []\n",
    "for i in range(df.shape[0]):\n",
    "    patient_ID = df[\"Patient ID\"][i]\n",
    "    outcome = df[\"Outcome\"][i]\n",
    "    specs_for_each_patient = np.array([])\n",
    "    #wav_file_for_each_patient = []\n",
    "    number_of_recordings = 0\n",
    "    data_directory = \"C:/Users/rishi/OneDrive - Monash University/Documents/Monash/sonorus/circor dataset/the-circor-digiscope-phonocardiogram-dataset-1.0.3/training_data\"\n",
    "\n",
    "\n",
    "    for root, dirs, files in os.walk(data_directory):\n",
    "        for file in files:\n",
    "\n",
    "            if re.search(\"^\" + str(patient_ID) + \"[A-Z_]{3}.wav$\", file):\n",
    "                number_of_recordings += 1\n",
    "                #load wav file\n",
    "                audio_signal, sampling_rate = librosa.load(data_directory + '/'+ file)\n",
    "                \n",
    "                #get the spectrogram\n",
    "                spec = librosa.feature.melspectrogram(y=audio_signal, sr=sampling_rate)\n",
    "                spec = spec.flatten()\n",
    "\n",
    "                #pad spectrogram - pad after taking spectrogram because \n",
    "                #the length of spectrogram is different for each audio signal(even if len of audio signal is same)\n",
    "                #we need data with same length for training\n",
    "                padded_spec = pad_signal(spec)\n",
    "\n",
    "                specs_for_each_patient = np.append(specs_for_each_patient, padded_spec)\n",
    "                #wav_file_for_each_patient.append(audio_signal)\n",
    "\n",
    "    #add outcome for each patient\n",
    "    current_outcome = np.zeros(2, dtype=int)\n",
    "    j = outcome_classes.index(outcome)\n",
    "    current_outcome[j] = 1\n",
    "\n",
    "    for i in range(number_of_recordings):\n",
    "        outcomes.append(current_outcome) #add the outcome for each location of a patient\n",
    "\n",
    "    #wav_files += wav_file_for_each_patient\n",
    "    specs = np.append(specs, specs_for_each_patient)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
